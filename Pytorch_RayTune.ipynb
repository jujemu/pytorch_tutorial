{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_RayTune.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch"
      ],
      "metadata": {
        "id": "xL2VfWJ9vIRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ray Tune\n",
        "___Hyper Parameter Tuning___  \n",
        "___Using Model classifying CIFAR-10___"
      ],
      "metadata": {
        "id": "OcIm9C03vSnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is referred to \n",
        " - _https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html_\n",
        " - _https://docs.ray.io/en/latest/tune/index.html_"
      ],
      "metadata": {
        "id": "hPiDLW7_vKvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MVeHypGJI2PL",
        "outputId": "794f0581-a514-48bb-8971-07ecc93ba38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/Colab Notebooks/Pytorch'"
      ],
      "metadata": {
        "id": "O3PRiTNNA53J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQfifTxKvH3i"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# install the package needed\n",
        "!pip install ray[tune]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# for hyper parameter tuning, only need to import 3 modules\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ],
      "metadata": {
        "id": "gzA76diKxJKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4AJgWlVbT-b-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "hFB_GbYyNWBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir=\"./data\"):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=True, download=True, transform=transform)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    return trainset, testset"
      ],
      "metadata": {
        "id": "sNFcZa6sx--2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "transforms.Normalize(  \n",
        "    mean,  \n",
        "    std,  \n",
        "    inplace=False \n",
        ")\n",
        "```\n",
        "mean and std is applied for each channel of image  \n",
        "Ex) 'mean=(0, 0, 0)' matchs 3 channel"
      ],
      "metadata": {
        "id": "pMR0Q9V7BIew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = data_path + '/RayTune'\n",
        "train_ds, test_ds = load_data(path)\n",
        "len(train_ds), len(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1Sf_ZWDNQ1-",
        "outputId": "9e3c3bc1-30b2-4f79-c145-fc9f2e2d288e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "oNevW9VJNRg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, l1, l2):\n",
        "    super().__init__()\n",
        "    self.conv_1 = nn.Conv2d(3, 6, 5)\n",
        "    self.conv_2 = nn.Conv2d(6, 16, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    self.fc_1 = nn.Linear(16*5*5, l1)\n",
        "    self.fc_2 = nn.Linear(l1, l2)\n",
        "    self.fc_3 = nn.Linear(l2, 10)\n",
        "\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.pool(F.relu(self.conv_1(x)))\n",
        "    out = self.pool(F.relu(self.conv_2(out)))\n",
        "    out = torch.flatten(out, 1)\n",
        "\n",
        "    out = F.relu(self.fc_1(out))\n",
        "    out = F.relu(self.fc_2(out))\n",
        "    logits = self.fc_2(out)\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "Ojtll29UBfv-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cifar(config, checkpoint=None, data_dir=None):\n",
        "  sw = True\n",
        "  net = Net(config['l1'], config['l2'])\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  if device == 'cude':\n",
        "    if torch.cuda.device_count() > 1:\n",
        "      net = nn.DataParallel(net)\n",
        "  net.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(), lr=config['lr'], momentum=0.9)\n",
        "\n",
        "  train_ds, test_ds = load_data(data_dir)\n",
        "  len_train = int(len(train_ds)*0.8)\n",
        "  train_ds, val_ds = random_split(train_ds, [len_train, len(train_ds)-len_train])\n",
        "  \n",
        "  trainloader = torch.utils.data.DataLoader(\n",
        "                    train_ds,\n",
        "                    batch_size=int(config['batch_size']),\n",
        "                    shuffle=True,\n",
        "                    num_workers=8\n",
        "  )\n",
        "  valloader = torch.utils.data.DataLoader(\n",
        "                    val_ds,\n",
        "                    batch_size=int(config['batch_size']),\n",
        "                    shuffle=True,\n",
        "                    num_workers=8\n",
        "  )\n",
        "\n",
        "  for epoch in range(10):\n",
        "    running_loss = 0.\n",
        "    epoch_steps = 0\n",
        "    for i, data in enumerate(trainloader):\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      epoch_steps += 1\n",
        "      if i % 2000 == 1999:\n",
        "        print(\"[%d, %5d] loss: %.3f\" % (epoch+1, epoch_steps, running_loss/epoch_steps))\n",
        "      \n",
        "    val_loss = 0.\n",
        "    val_steps = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, data in enumerate(valloader):\n",
        "      with torch.no_grad():\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        ###\n",
        "        if sw:\n",
        "          print(type(outputs))\n",
        "          print(outputs.data)\n",
        "          sw = False\n",
        "        ###\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        correct += (pred.item() == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss += loss.cpu().numpy()\n",
        "        val_steps += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "BQ_Dpg0Xrcym"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "DEYUIGzJBtTn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}