{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL2VfWJ9vIRF"
      },
      "source": [
        "# Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DfEAA_Bh2Qd"
      },
      "source": [
        "## Review\n",
        "_Quick Start_  \n",
        "_https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYNgAi2_iP1W"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/Colab Notebooks/Pytorch'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xkac6DZ6nW4n",
        "outputId": "4ba1b18e-2a54-487f-ef41-fb1c546a33c4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfxNDhUqh8dn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2JMu438iFh_"
      },
      "outputs": [],
      "source": [
        "train_ds = torchvision.datasets.FashionMNIST(\n",
        "                    data_path,\n",
        "                    train=True,\n",
        "                    download=True,\n",
        "                    transform=torchvision.transforms.ToTensor()\n",
        ")\n",
        "test_ds = torchvision.datasets.FashionMNIST(\n",
        "                    data_path,\n",
        "                    train=False,\n",
        "                    download=True,\n",
        "                    transform=torchvision.transforms.ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfenwfKupQtv",
        "outputId": "1f81badc-4641-4847-9286-d762489a0c57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds[0][0].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "1WkC8rH5i4py",
        "outputId": "f62fae7c-4a2f-4f34-a467-39288d191a7d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFTCAYAAAC06zwQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debBdVbXv8bGkC0lIByQnLYGEhF6a0KVA2ioIVgQflqJ0RqSVwgYFRKSKF7zUhRIfJV4oqIdeRCgEqcfDB6GzwAgSSACRSBICpO9JSEI6IKz3B3i9a4zfOXuwc87ZJ+d8P1X8MUfNvc7ce8+9JztzrDGLsiwNAAC07HONHgAAAFsDFkwAABJYMAEASGDBBAAggQUTAIAEFkwAABJYMAEASGDBbEFRFM8URbGxKIr3P/1vZqPHhM6tKIp7iqJYXBTFmqIoZhVF8e1GjwldR1EUe376nXdPo8fSEbFg1nZpWZY9P/1vdKMHg07vBjMbXpZlLzP7kpldXxTFIQ0eE7qOX5nZS40eREfFggl0IGVZTi/LctM/m5/+N6KBQ0IXURTFGWb2npk93eixdFQsmLXdUBTFiqIoniuK4thGDwadX1EU/1EUxXozm2Fmi83s0QYPCZ1cURS9zOx/mtkPGj2WjowFs2VXmtkeZjbYzO4ws0eKouD/9tGmyrK8xMx2MrOjzewhM9vU8iOALTbRzP53WZYLGj2QjowFswVlWU4py3JtWZabyrL8TzN7zsxOafS40PmVZbm5LMu/mNkQM7u40eNB51UUxYFmdqKZ/aLRY+notm30ALYypZkVjR4EupRtjT1MtK1jzWy4mc0risLMrKeZbVMUxT5lWR7cwHF1OPzCbEZRFH2KojipKIpuRVFsWxTFmWb2BTOb1OixoXMqiqJ/URRnFEXRsyiKbYqiOMnMvm4kYaBt3WGf/E/ZgZ/+d7uZ/T8zO6mRg+qI+IXZvO3M7Hoz28vMNtsnCRinlWU5q6GjQmdW2if//Hq7ffI/s3PN7HtlWf7fho4KnVpZluvNbP0/20VRvG9mG8uyXN64UXVMBQdIAwBQG/8kCwBAAgsmAAAJLJgAACSwYAIAkMCCCQBAQou3lRRFQQot/ktZlu1StKEjzLtPb+Cu8BnlO+ywQ+hzyCHxYJHnn3++9QaWcNVVV4XYk08+GWLTpk2rtDPPuRHaY96195z73Ofib5WPP/641a4/fPjwENtrr70q7UmT6rulvF+/fiF2yimxANo997TeCWFqbmbUO3+bm3P8wgQAIIEFEwCABBZMAAASKI0HCJm9j2uuuSbEDjvssBC7+uqrQ8zvH9br9NNPD7HjjjsuxHbeeeeaY+gI+5WdQWa/rd79ysGDB4fYBRdcEGK77bZbiO2zzz6V9oUXXhj6fPDBByH20UcfVdpjx44NfV5//fUQGzNmTIg9+OCDlbba31evTWZuqn3h1p7T/MIEACCBBRMAgAQWTAAAEtjDBIR670lcvXp1iF1yySUhNnPmzEpb3du2adOmENtxxx0r7T59+oQ+ixYtCrH169eHGNpGZp6oe3jVPPnKV75Saas50aNHjxBbsmRJiD39dPVY1W9/+9s1/56Z2ZFHHllpNzU1hT5vvfVWiB1zzDEhdvDB1fOoBw0aFPpMnjw5xG6//fZKe8qUKaGP2vts7ftd+YUJAEACCyYAAAksmAAAJLBgAgCQULS0Qd0RimCj4+hKxdczbrzxxhDbddddQ8zf+G0Wk3xUIsJOO+0UYtttt12l/fbbb9ccp5nZhx9+GGIqyaQj6gzF1w8//PBKWxW9UO+3T9ZS76MqNqASc2bMmFFpr1q1KvQZP358iPlEI1XIXyX4LF++vOZYt9025p327NkzxHw/nzRnppOYFJ/Qp9ZAiq8DALAFWDABAEhgwQQAIIEFEwCABCr9AHVat25diA0YMCDENm7cGGI+eUNVcFF69eqVHF2VSjzKqLfiUWeUrRqjXjOf5KOutWzZsppjUAkx6lpLly4NsWHDhtW8Vrdu3ULMz3NfrcdMzwmV0OOp109Vy/KfF3USysUXXxxit912W4htyfzlFyYAAAksmAAAJLBgAgCQwIIJAEACST9AnVTCgoqphBtfsee9994LfdQRUNtvv32lrRKKWjMpp6sm+CjZpJ8rrrgixHwVH1UFxx/dZhbfX1XVRyUZqbGuWbOm0lbvrZqH77//fqX97rvvhj5qjquYT97ZZpttQh91XNnmzZsrbXWE3WmnnRZiKulnS/ALEwCABBZMAAASWDABAEjo8nuY/t/61b/9Z276zu5vtKbu3btX2ueee27os2HDhhD7zW9+E2L+JuN6b3TvStTJJIo6YcLvC6n9K7/PaWa2du3aSlvtc6qb1g855JAQ849VxRMoXPAv2c/EBRdcEGL+dA11Monfn1bU51m9RyrWu3fvSnvhwoWhj9pT9PMwu1+Z+f5Tz7lv374h5k9WUa/DoEGDQuyss84KsXvuuafmuJrDL0wAABJYMAEASGDBBAAggQUTAICETpv0k03C8bFsos64ceMqbX8SgJnZ9OnTQ0ydBnD44YdX2nvssUfo88ILL4TYypUrK211eoZKClG6cpJPNrHFJz80NTWFPuqkBZVI4W8iHzJkSOij5rC/aVzNJ0XdDO5Pq1BJP2oM/ibyruzkk08OMf/emsXXTH0uVZJXnz59Km1VqELNL/U9tn79+ppjUPy1VBKbKqiQSWJSnz11isrixYsrbZ80Z6bn74QJE0KMpB8AANoYCyYAAAksmAAAJLBgAgCQ0GmTfrLJO75azl577RX6+OQaM7Mzzjij0p41a1boc9BBB4XY/vvvX3NM8+fPD7Hf//73IfblL3+50lbVL+6+++6af88sJne0dZWirVHmpIXM48xySSAquca/x+pxKgEjW50Fn82FF16Y6udfa5WspSpH+e8eX5FLXdtMzzk/X9X8VXNHxTyVJKfG5eereh3UnPZjVX1UQtTw4cNDzCdSqRNamsMvTAAAElgwAQBIYMEEACCh0+5hZvkbuocOHRr6qJu3f/nLX1baar9y7ty5NR+Xpf6t3+9nvfHGG3Vd26xr71nWe/qGKhSh3if12vr3Tu0/+70Ws7ivqfr4G9Sb40/MUEUX8C8DBgwIsV122SXE/MkaZjFXQu0xqlwJf/N/r169Qh9fzMJMFwTw32P17nWrz4sqGuCfs6L2Uf2pKmZmo0aNqrSnTJkS+qh5r76DL7744kr7hhtuqDnOf+IXJgAACSyYAAAksGACAJDAggkAQEKXT/rxG+YPP/xwXdeZOnVqawynWf5EEzOzZcuWVdoLFy5s0zGgSiUn+FMVzPTpFf7Ga/XeqaQiH1M3XWeSLcx04gmad/zxx4eYSgjs169fiPnPqrrJfr/99guxV155pdJW75m6iV/18wlp6sQPlSzkiyWoU1VUTBVZ8ElMy5cvD31U8RifXKVONFEJUSrh7qijjgqxLH5hAgCQwIIJAEACCyYAAAksmAAAJHT5pJ9MhRu1sV/PdbJGjhyZGsPatWsrbVXxQ2nv59NZqeo8qnqKSqTwSQxDhgwJfVTShE/cUBVW1AkNKglEjR/Nu++++0JMnSJ0+eWXh9j48eMr7REjRoQ+6j3yn/G+ffuGPmrOqWo8fh6q03AyVa/UvFQVe9Tc9NWlVLLQokWLQswnRB1xxBGhz4MPPhhid9xxR4j97W9/C7EsfmECAJDAggkAQAILJgAACSyYAAAkFC1t8hZFUd+5Rx2USnZpreSW7LUz/c4666zQx1cKMTObMWNGpT1v3rya49wSZVnG7JU20N7zTiXlZJIffBUWM11tZMcddwwxn3AxaNCg0EdV8fEJHitWrAh91NjVkVPHHHNMiHn1vjatqT3mXXvPuXHjxoXY1VdfXfNx2cpOal7448nmz58f+qiEQ1+pSl1bVRtSCT2qOlbmWrNmzaq0zz333JrX2RLNzTl+YQIAkMCCCQBAAgsmAAAJDS1coG6A9T766KNW+3tteTN+vfuVZvFmZHVDudrDzNx47m90N9N7C35/o633QzuDV199NcTUHpPffzGLN6TvvvvuoY+aP2+99ValrU64mD59eogde+yxIbbrrrtW2urkCPxLa+7nPvbYYyGmchf23nvvSludhuOLAZjp783MWNWc889bvQ5K5hQVdepIU1NTiKn562XGbqYLNmTxCxMAgAQWTAAAElgwAQBIYMEEACChoUk/rZnQ49VbSKA1E4Oy1/JV/f/whz+EPipB6uijj660fSKJWTwVw0xvxvvkkd/97nd6sJ1QNnFj7NixlfbOO+8c+qiknx49eoSYf19UwYMDDjggxPyJNAcddFDos3LlyhDr169fiH3ta1+rtG+99dbQp72LFHRk2dei3uSg/v37h5h/v1URDEUltvjvI3XCiIplkn6y37c+6UclJarvLF9QQSW2qe9IdZLLluAXJgAACSyYAAAksGACAJDAggkAQEJDk36+853vVNpqg/bOO++s69rZhJu2rP6j+OoqZmYjRoyotNevXx/6qE314cOH13zcwoULQ+zNN98MsXXr1lXaKoGoq/NJOOoEkPfffz/ENm7cGGI+QUE9TiV4+PfJnyRhpitAqSo+Q4YMCTFsuXoTpdTjMlV1VOUudS3/HaIep/jHZSvqqH6+so9PAjIzmzNnToipfp5KdMq8fp/l/eIXJgAACSyYAAAksGACAJDQJnuY6t+u/YkcZmYnn3xypT1t2rTU9f0N4xMmTAh97r333hBbtGhR6vr1UDfNfuMb3wgxdcq9P5Fg6tSpoY86kcD/u77aj73vvvtCTN3Y7vezsvsbXYkvLqD2CtXerz8JRlFFPFTBA//ZUjd+q71PVVDB76erQgz+xnm0HbVP5z+H6v1W1HewzxFR+3uqqEkmz0N9/6mcCj/n1PxSe4qZAgTqca1deINfmAAAJLBgAgCQwIIJAEACCyYAAAktJv1kK9Bn+qhEhFtuuaXSfuqpp2pe2yzevO1vhjUze/jhh0Ps0EMPTV0/wycsnX322aHPW2+9FWJ33XVXiD333HOVdlNTU+jz61//OsTmzp1baS9btiz0ySaT+OQCdRNwVzJo0KAQ84lX6vPhT55RjzOLc1YVmFAnmPjTJFRRBPX3/GfGLCZ6+QIaZiT9tKdMop06TUR9VrfffvsQ8wkw6lqKv76a99m1wj/HbIKPSirK9OG0EgAAGoAFEwCABBZMAAASWDABAEhocSe13pM8Tj311BDz1WzMzJYuXVppX3HFFanH+ZMdHnroodDnyCOPDLGf//znIXb55ZdX2mrz+tprrw2xAw88sNL+xS9+Efo8++yzIZbhr21Wf7KV2ghXz9H36+qVfvr37x9ivhKOqrqikn5UxROfVKQSxFTVlX79+lXa6rQSlbzz8ssvh5ivLLPvvvuGPi+++GKIoWWqgk6m4kzmtBL1eVaJfZnPr0oMUnPVJ/2oea+es0pG8t9R2cS5bIJSW+MXJgAACSyYAAAksGACAJDAggkAQEKLST+ZDWZ/XIuZ2Yknnhhif/rTn0Js8eLFlfb8+fNDn2eeeSbEfAUUlexy++23h5hKrPCJHL/61a9qjtPM7LTTTgsxL1sRw7+m6tgoVall5syZlbY6wmnVqlUhtmTJkhDzCQArVqwIfboSVT3KJ+GoRIdstRHfL1vdxFdpmjdvXuhz+OGHh5iqtOWPefOVf9DxqOQXVe1JJf34+ar6qAQi//2qktHUd5b6rvOJTSqBqCNXGeMXJgAACSyYAAAksGACAJDQ4h7mj3/84xDzRQNmzJgR+vz2t78NMbUHN3jw4Er7pz/9aegzfPjwEPN7LZdddlnoc/fdd4fYxIkTQ+z000+vtK+88srQ55577gkxL1utX/Xz1B7BwIEDQ2zMmDGVtjpZwt+cbqZvDB47dmylPWfOnFrD7NTUXpE/BWTt2rWhT9++fUNMFRfwe6Rq36Z79+4h5nMG3nzzzdBH7Sepm9R9P3WKDT67TJECRe1ZZwqWqH3HTK6Eml/q7/nPgnp+6u+pOefXD9WntU8YaU38wgQAIIEFEwCABBZMAAASWDABAEhoMennZz/7WYjtueeelbY/dcHMbOjQoTUfZxY3oe+9997Qp3fv3iHmCxD4ExzMzK6//voQmzJlSoiphKEMv8mdPdlFbdDXuraZWZ8+fULMJ/T4JCozs9GjR4fYueeeG2J+/Or0lc4qk+BjFhN6Zs+eHfqoxJnly5eHmE/6UfNCXcsnaqh55wsSmOnP0erVq2v+PfX5XrRoUYhhy6lCAj4ZTL3fKmFMJQ76k0jUvFcFLvzcVCeaqLmjEj19TH3OVNJPpphB5rt1S/ELEwCABBZMAAASWDABAEhgwQQAIKHFpB+1wexPyPDtriKb5FOPSZMmpWJoHSpBQiVZ+WQsdTqMOvEjU4lFJXqpyi8+0UsliqjTaIYNGxZivuqKeh1UpS2SftpG5oQRNSfU3Mkk72SThfw8Ud99qvpPvd+RagwdBb8wAQBIYMEEACCBBRMAgIQW9zCBrkAVvmhqagoxf7KC2nNSpy+o6/uT5tW11N6nv2lc7bWqU1TUPpe/2VyNwZ+Ogtr8vqNZ7gQT9fr7fUA1J1QBAnUSycaNG2uOU+2R+uurv6fmlypK4Mevno8qspE5SUc9n9bGL0wAABJYMAEASGDBBAAggQUTAIAEkn7Q5akTOdSN/j7ZYdOmTaGPulk7c6O3utF8zpw5IeaTJFTSjzqtRPGJGio5aY899khdC/+SSfBRfIEAdS0153wxC7N4Eo26vkrUUYlHvkCHTx5qLpZJKtqwYUPooz4LmddUJSxlTjn5LPiFCQBAAgsmAAAJLJgAACSwYAIAkEDSD7q8AQMGhNioUaNCbOnSpZW2Sk5QlXFU4oGvgqJOBVHJOz4BQyXlqKoovXr1qnl9VXWlZ8+eIYa2oRJ6/DxUVZzU/FXX8qeAfPDBB6GPSiJbt25dpb18+fLQR1XGUkk/fv6qPmoM6rOW+XutjV+YAAAksGACAJDAggkAQAILJgAACST9oMsbM2ZMiL300ksh5qugqKO8nn766dTf3G+//Sptn1BkZrZmzZoQ89VMVEUXda3p06eHmE88eu211/Rg0S4WL14cYj7JR1XGUck7qvKOTz5TyWinnXZaiPkj5Z544onQRyWHqWPAfOKR4o++M9Nz2lNJa62NX5gAACSwYAIAkMCCCQBAQtFSFfiiKOoru49OqSzLtr8z2Np/3o0cOTLEunfvHmL+5n91E/k777wTYqrfnnvuWWnPmjUr9FHFEwYPHlxpq5NQ5s6dG2Lqc+73k9Seqdqbmj17doi1pfaYdx3hu+7SSy8NMV+Ewt/4b6ZPmVF7mJ7a81P7oX6vU+0xZgoeKGqcqvjHbbfdVmmr4glqz7Te00qam3P8wgQAIIEFEwCABBZMAAASWDABAEhoMekHAAB8gl+YAAAksGACAJDAggkAQAILJgAACSyYAAAksGACAJDAggkAQAILJgAACSyYAAAksGACAJDAggkAQAILJgAACSyYAAAksGACAJDAggkAQAILJgAACSyYAAAksGACAJDAggkAQAILJgAACSyYAAAksGACAJDAggkAQAILJgAACSyYAAAksGACAJDAggkAQAILJgAACSyYAAAksGACAJDAggkAQAILZjOKonjf/be5KIpfNnpc6NyKohheFMWjRVGsKopiSVEUtxZFsW2jx4XOjXmXw4LZjLIse/7zPzNrMrMNZvZAg4eFzu8/zGyZmQ00swPN7Bgzu6ShI0JXwLxLYMHMOd0+mUyTGz0QdHq7m9nvy7LcWJblEjObZGb7NnhM6PyYdwksmDnnmtndZVmWjR4IOr3/ZWZnFEXRvSiKwWY2zj758gLaEvMugQWzhqIodrNP/nniPxs9FnQJf7ZP/s9+jZktMLOpZvZ/GjoidAXMuwQWzNrONrO/lGX5TqMHgs6tKIrP2Sf/V/+QmfUws13MrK+Z/Xsjx4XOjXmXx4JZ2znGr0u0j35mNszMbi3LclNZlu+a2a/N7JTGDgudHPMuiQWzBUVRjDWzwUZ2LNpBWZYrzOwdM7u4KIpti6LoY5/sn7/W2JGhM2Pe5bFgtuxcM3uoLMu1jR4Iuoz/YWYnm9lyM5ttZh+a2fcbOiJ0Bcy7hILETwAAauMXJgAACSyYAAAksGACAJDAggkAQAILJgAACS0e31IUBSm0+C9lWRbt8Xe2lnn3uc/F/9/8+OOPU4+96KKLKu0vfvGLoc+aNWtCrFu3bpX2a6/FW+Wuu+661Bi23bb68VcZ85s3bw6xoqhOg7bOtG+Pebe1zDm0j+bmHL8wAQBIYMEEACCBBRMAgIQW9zAB/Ivfu8vuV958880hNmzYsEp7woQJoc+KFStqXnvixIkhNn/+/BAbOnRoiH300UeV9jbbbFPz73VW/r01i3uzu+22W+hz2WWXhdjq1atDbO+99645hg8//DDEdtxxx5qPU3vpKpZ5f/2cMIuvjXqt1LXV/rfvt3LlytBnzJgxIXbqqadW2rNnzw59srZkD55fmAAAJLBgAgCQwIIJAEBCi6eVcG8S/ruufh/m9ttvX2l/8MEHoc95550XYl/60pdCzO/JtKZzzjknxA444IAQ++EPf1hp+/syzfSeVnvrKPdhPvLIIyE2ZMiQEFPzYqeddqq01euqvovVe+KpPcXMHqbqo8bg+6m9+w0bNtQcp7q+2qdXz8e/Xi+++GLoM3ny5BCbNGlSiGWeD/dhAgCwBVgwAQBIYMEEACCBBRMAgASSfpDWlZJ+6i2s/uijj4aYKoY+ZcqUSjubcOMTItSN7evXrw+xm266KcSeeOKJSvvJJ58MfXyik5lOamlLjUr62W677Srt6dOnh8fNnTs3xPr27Rtifu6o9ztTPEH1ySb9+H6qsICK+WupNUMVLsgU81dzae3atSHWu3fvSlslW6mCHUcffXSI+QIR6rXavHkzST8AANSLBRMAgAQWTAAAElgwAQBI4LQSQFBJGT5B4aijjgp9Nm7cGGI+wccsVzUok+CRrcTzwAMPhNj48eMrbZX005V997vfrbTXrVsX+nTr1i3EdthhhxDzSTHqfVMJN/5a2RNyMieYqD7Za3nq86Kejx+/SlpTp734U01UZSF1mswll1wSYrfcckulnamm9E/8wgQAIIEFEwCABBZMAAASWDABAEgg6QcQVMKNp6qIvPTSS6nr+0QDX31E9VH91OPU2NVxSGeffXbNcapkpMzxSJ3BmWeeWWn7I7rMzDZt2hRiqsKNT/JSj1Pvd+a1VX8v8zjVJxNT41RJOGoeZhJs+vfvH2I+OSibgNXU1FTz76nPUHP4hQkAQAILJgAACSyYAAAksIeJLk/dmK32mLzdd989xB577LHU38wUHMjuT3otnUD03/n9yZNOOin0efzxx0PM30yv9q86A1+E4t133w191H6bP+XELO4Ddu/ePfTJ7od6mTmhxqD2K9W1fNEF1UftHyp+3qvPnj+ZxCzmBgwcODD0Wbx4cYgdeOCBNceU/byY8QsTAIAUFkwAABJYMAEASGDBBAAggaQfdBoqGUElYPjEg+zjfBLOYYcdFvr827/9W81xmsWEi2ziRkZm7GZm77zzTqV94oknhj4q6cefQuGTQszqP72iUUUQhg0bFmI+sWThwoWhT+ZEGTP93DN8UoxKUMnOncxpJapQhR979u9lCiqoMaiEuNGjR1fa6kSYF154ITWufv36Vdr+JJSW8AsTAIAEFkwAABJYMAEASGDBBAAgoVMk/aiNY7XhXG/VjMzjhgwZEmLqNIgbbrih5rXa2sUXXxxiPgFk0qRJ7TWcVqPeJ5XEkJFJ0ujbt2+IzZkzJ3X9TKWfemVPX/Dv+Ve/+tXU4zKvab1JLo2iPr9r1qyptNVzUglP9VaOyqg3wUfJnlbi/6Z6zuqzp16vzLjUZ+P999+vtNeuXRv67LzzziGmTg8aNGhQpU3SDwAArYwFEwCABBZMAAASOsUeZvZmZ/Vv7/7f2dW/xau9qmOPPbbSVqexjxs3LsQye5jqpu/W3PNatmxZiPk9go7G732o99yfym5mduaZZ4aY3+NTr/eCBQtC7IQTTqi0VYGAiRMnhtgjjzwSYgMGDKi0V69eHfqo99zvJ6n5qp7PvHnzQuxb3/pWpb3rrruGPkcddVSI+b/Zp0+f0Mef9GFmNn369BBbsmRJiDVCr169Qsw/L/UZqTfnISvz3VZvoQQ1TvUd6WNqH1KNU10rswe7fv36EOvZs2fN62y//fYhpk7gueOOO2qOoTn8wgQAIIEFEwCABBZMAAASWDABAEgoWtqgLoqi9Xav21B2EzpDJepceumlNa+vknm+/vWvh1i3bt1C7Pzzz/8sQ2zW97///RDbb7/9QuyVV14JsT//+c+V9muvvRb6lGXZekdqtEDNO7+hr26e32effULsj3/8Y4gtXbq00lYnH6g55ZMY1BxT769KwPBJC9niGxnqcSohSiVleKoQg0+Q2bBhQ+ijEjDUTeQXXnhhzTG0x7w78sgjw4v28MMPV9ovv/xyeNwee+wRYirhyc+L7I3+PvFLzTk1dzLJNZn3X11fFcZQCWqZog7Z72n/mVVzbuTIkSGmXtMDDjig5t9rbs7xCxMAgAQWTAAAElgwAQBIYMEEACChoZV+MhvTmcSH7MbxN7/5zRA7/vjjK+3ly5eHPo8++miITZs2rdI+7rjjQp8pU6aEmNqYvvnmmyvt+++/P3Ut7/Of/3yIvfXWWyGmklx23333Slsl/TRSpnKJqtaikoP8yRFq/qgqPrWuY6aTEVTlHf83s1VX6qWSMvxzVAk+agy+qpVKAlGxUaNGhdjBBx9caavEmvawePHiEPOnX/Tv3z/08SeamOn55D9zKjFI8e+Reh9V0k8mEVKNU83DzOPUd7n6fPiKPepa6jX1n6HBgwenxqDe1y3BL0wAABJYMAEASGDBBAAggQUTAICEFpN+MkfXqM3lrHqr8fjN+C984Quhz5VXXhlif/3rX0PsxRdfrLRnzpwZ+qhqOaecckqlrY4A22WXXUJMHa3lj3Y655xzQp/TTz89xAYOHEwjeFMAAAzySURBVFhpq6SNlStXhpiq+jJ06NAQ60gycyX7HHwihUqCyoxBJfNkK/ZkEt5Un8zjMklGZmY9evSotP2RY809zr9+KkFKJWmp61933XWV9vjx40Of9uCT/8xigs3cuXNDH/VaH3LIISHmP/fqcep19MlT2ddaJQf5v6mScjIVrlQf9XzU94w/Ik31UdWyfCKQepxKBPIVzLYUvzABAEhgwQQAIIEFEwCAhBb3MFuzaEC9jjjiiBD7yU9+Umk///zzoc9dd90VYmp/0p9wMXr06NDH32xrFv+dXRU8UIYMGRJi/t//Fy5cGPqoG+LfeeedmuNsamoKsXfffTfE/B6s2n9tpMxc3HfffUNMFS7w1BxWe0Ceujk/u5/k9yLVGNS1/P6Rel3UPtf69etDzD92xYoVoY8qXOCvpeamepwqovHmm2+GWCP4AgpmZvPmzau01Wk4ijqVxRcG6d69e+ij3iNP7RVm+fckexqOn3NqH119ztT1/fNW391jxowJsV133bXSVt9rfn/UTJ+asyX4hQkAQAILJgAACSyYAAAksGACAJDQJqeVDBs2LMRUskvv3r0rbbXpPWjQoBDzCT1qc1klrey99941+6lEDj9Os5iYox6nnvOCBQtCzJ+y4QszmOnCCGvXrq20VeKRGpe/Yd0snkCRvZm/I/GFHMx04oxPflDPNXMChErcUDInQGSLG/jHZRKDzPRJLn5O/eMf/wh9dttttxDziSdqjqnXxhfoMIvJMD65o72ok0j881LPUyU3qeQ7/56o11olrfmEsWyxARXziTn1zjn1eVHXevvtt0OsT58+lbYq8qCKrfiiBJmiCGa6mIl/nadPnx76NIdfmAAAJLBgAgCQwIIJAEACCyYAAAktJv2o5JMDDjig0laVFFSCgeI3oVWFEl/Nxiwmd6iEGFXxXvEb2j75xSxWyldjyCZaqIQb/1j1mqpqKv5xKmFCnY6iqqv4zXifULQ1UJVYVAWSzIkfai56KuFGqffUESVTdSVTYcUsJtn9/e9/D33233//ENu4cWOlnXmtmhuXT7o7+eSTU9dqbSqxz38m/PM20/NLncriE1LUa6GSVl5//fVKW1XBUclU6nvMU99P6rvOvw5qnqjkJ5X86ZMlVQKRmnM+kUp9rykjR44MMV+J6Ywzzkhdy4xfmAAApLBgAgCQwIIJAEBCi3uY6qbP4447rtJWp5Cr/S/1b/1+T0D9e7Y6RdvfzKv2K9XejurnT+5Q/4av+L1PtW+hbmBWBRUyNwar/Q1v3bp1IaZuPFc3+PtTWg466KCaf6+R1E3ew4cPD7HZs2eHWGZ/R/H7TmofKnszeL38HqbaO1fUaSh+zqo94KVLl4aYv8k/WzwhU5jksMMOC33agxqv/8yp7wa1T6fmgM9LUDfeq8+vz89QhQumTp0aYkcddVSI+b07dTKTP6HFLH5vqu+P9957L8RUoQe/p6i+k9V35LPPPltpr1q1KvRR+9Bqf92/1+o5N4dfmAAAJLBgAgCQwIIJAEACCyYAAAktJv28+uqrIeY3itWNtCppRd1cq6rSeypZwW98q2IA6qZclZjjkw7UhrMqjOCvrzac1eugbvD1SUyLFi0KfdTr5zfM1eupblhXyUizZs2qtKdNmxb6dCTXX399iKnEA3+yhlnc9M8m73jZZJ5MP9VHJaL4ftnHqZifi/4GddXHLCasqGQelQikCqH4Uzu+973vhT6XXnppiLU29dnxiWWqj5pz6jPnn7tK8FHJaJmkH5Xgowqd7LnnnpW2+m71fcziZ0jNCZVcqBJufEzNHfVd5xNQ1eky/nvUTL8/PmEom+hpxi9MAABSWDABAEhgwQQAIIEFEwCAhBaTfpT777+/0n7wwQdDnxNOOCHExo4dG2J+Q1udtqESbvzmuEpiUckeKgnHb3yrDec5c+aE2IIFC2r2mTlzZs3HmcUEAJUQoJJQfLKT2uhXSSErVqwIsYw777yzrse1hn79+lXao0aNCn38SQhmOonLv5Yq+SFTsSeTGNScbIWeWmNQ81wlP6jKMkuWLKm0J06cGPqMGDEixG688cZKWyV3qMpe6vPtk82yJ8C0tsceeyzEjjzyyEpbJReqSjXqOfjkE/W5VKcUNTU1VdpqrqokI/VZ8HNAvW+qSptPWFLPT31nqTngq/+oz1Dm1CqfrGkWXysz/fnw4/8sn0V+YQIAkMCCCQBAAgsmAAAJLJgAACR85qQfT22YPvHEE6mYpxIT1CZ3ZpNWHS2j+GtljyryG+2ZakBmOvHIVwlSR3mp42z8hnm26ouqDOKP86o3MaitTJgwodL+wQ9+EPr86Ec/CjGVQOCPlVOvUSbpR73e2eO96r1WhnrOqkKMT5K46aabUtdatmxZpa2STtTnz7/uZvp4rEZ44YUXQszPC/UeqeepYj75JPtd548fVNdWCTCqn38vVaKO4seQTZJR36W+SlB2nvhET/Ve+CQ2M11JyP/Nz/Jdxy9MAAASWDABAEhgwQQAIGGL9zCze4WZQgLqRle15+f3BtW/latiBmpPyI9f/fu82lP0z0dVvFc3Aasbnf2N5uoGZvXa+BMC1N7kM888kxqXv3F79uzZoc+9994bYu3FFy54/PHHQ59bb701xNRN/JkCBPXuOyr1XitzfbXvpU6TUHuRfn9H3Ziv9sd8kQ51Uo/a18x8HtTY24MqMuK/V9RpIuo0DMW/T+p9U59x/76pMaiCJWo/b/DgwZW22t9T/N9UY8/mfvi9dDXH1evgP/9q7Op18CfOmJk99dRTlXb2PTTjFyYAACksmAAAJLBgAgCQwIIJAEDCFif9ZKnkCxXzVFKRSsLxli5dmhvYVszfcDtt2rQGjaTtZRJg+vTpE2L+lAOzmFhSb4GALUn68bbk5BMvmwjkY/Pnzw99BgwYEGKZZD2VZKRu1vcnYfjkjkY6//zzK+0HHngg9FEJIyppzyfFqCRI9Tr6a6nkGjV31PV9v2yiTmvy80KNXcX8nFOFYqZPnx5ixx57bIhtyfckvzABAEhgwQQAIIEFEwCABBZMAAAS2i3pB9gSKnnHU8kWik8ky1bG8QkR2ao0bZlUpMagkjlUQpRP8rnqqqtCn+uvvz7EjjjiiEpbVZVRSRkqqcVXCerfv3/o0yhPPvlkpT158uTQ55hjjgmxuXPnhphPeFInhagqPp6alyrBR73fmRM/1HzyY9+S6m6eSvxUVXx80o/6TI0fPz7EVAW2LcEvTAAAElgwAQBIYMEEACCBPUxsFd54441Ke8iQIaGPOtlGnQ7j926y+0KeKhCgYvUWLsjsfaprq9dh1apVITZ8+PBKe8aMGaGPKmawcePGmmNQ+8mq4EjmNI72oJ6Df/3VHtlzzz0XYiNGjAixBQsWVNrqPfIneZjl5qF/P8z0PqA/5Umd7qFOmfH7jJmCM831858PtR+qPo++wMV5550X+qj9SvX6ZU6OaQ6/MAEASGDBBAAggQUTAIAEFkwAABJI+sFW4S9/+UulfeaZZ4Y+y5cvD7Fddtml5rVVYoBKpPDJAepkB5XooK6/evXqSlsl+Khr+X4qQUIlsKh+/kQfdcO9KoLgr6VudldJJ+r1Wrx4cYhtTcaNGxdiU6dODbHBgwdX2j4JyEy/Pv61zs5VNQd84QiV7KLebxXz1NjV4/wYfCKSmU6Iuvbaayvt++67r+aYmhvDlpwMxC9MAAASWDABAEhgwQQAIIEFEwCABJJ+sFUaNGhQqt+iRYtCzCcVqOSaTAKGSqxQlYVUAkzPnj0r7Wy1Ed9PJTCocanr+8eqhBL1OmSqz2QTj3zSx7Bhw2peuy3UmwiiqssceuihIfb4449X2qNHjw59Vq5cGWI+oUqd+KLeW5U4ox7rqffbU6+VqlLkTzkxM2tqaqq058yZE/pcfvnlIfbII4/UHJeS+Xx8lveeX5gAACSwYAIAkMCCCQBAAgsmAAAJJP1gq6SSJlTCgjouyicMqSOGVBKD79ejR4/QRyVuqH7+qCt1HJY6ksvLJiyoY5t8Eo66ViYJRCVNqQorKsHDH9M2b968mn+vo/NVnMzMjjjiiEp74sSJoc8111wTYitWrKi0e/fuHfpkErrM9HFenk9GM4ufBVXZSX1eVBWfO++8s9K+6KKLao5JyRzH1hb4hQkAQAILJgAACSyYAAAkFC39u29RFG3/j8LYapRlGTcO2kBm3qmb5/faa68Q83tkZmYDBw6stNUeY9++fUPM7wPuvPPOoc/atWtDTJ1ekT1tAe0z7zrqd53f+zzwwANDn4MPPjjE1Lzv06dPpa32p9V+/qxZsyrtyZMnhz5qjr/++ushtrVobs7xCxMAgAQWTAAAElgwAQBIYMEEACChxaQfAADwCX5hAgCQwIIJAEACCyYAAAksmAAAJLBgAgCQwIIJAEDC/wcKG6lNvQe2JwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x432 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(8, 6))\n",
        "\n",
        "for i in range(1, 7):\n",
        "  idx = torch.randint(len(train_ds), size=(1,)).item()\n",
        "  image, label = train_ds[idx]\n",
        "  image = image.view(28, 28)\n",
        "\n",
        "  fig.add_subplot(2, 3, i)\n",
        "  plt.title(label)\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  plt.grid(False)\n",
        "  plt.axis(False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7w0fvfMl0tP",
        "outputId": "2d4f4fda-c9aa-491b-b603-6df1c41ef7dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(938, 157)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "                train_ds,\n",
        "                shuffle=True,\n",
        "                batch_size=batch_size,\n",
        "                num_workers=2\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "                test_ds,\n",
        "                batch_size=batch_size,\n",
        "                num_workers=2\n",
        ")\n",
        "\n",
        "len(trainloader), len(testloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPNatsXsmNI5"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc_1 = nn.Linear(28*28, 8)\n",
        "    self.fc_2 = nn.Linear(8, 16)\n",
        "    self.fc_3 = nn.Linear(16, 10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.flatten(x, 1)\n",
        "    out = F.relu(self.fc_1(out))\n",
        "    out = F.relu(self.fc_2(out))\n",
        "    out = self.fc_3(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvhlrel4nUw6",
        "outputId": "883deb93-0e6c-4143-b5b8-6c994d13bb71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc_1): Linear(in_features=784, out_features=8, bias=True)\n",
              "  (fc_2): Linear(in_features=8, out_features=16, bias=True)\n",
              "  (fc_3): Linear(in_features=16, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Net().to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRw8WX7anNR4"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-R-939ynrRm"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, loss_fn, optimizer):\n",
        "  for i, data in enumerate(dataloader):\n",
        "    X, y = data\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    \n",
        "    model.train()\n",
        "    outputs = model(X)\n",
        "    loss = loss_fn(outputs, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "      print(f'Loss: {loss:.3f} [{i*len(X)}/{len(dataloader.dataset)}]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKZPk1cmuvcO"
      },
      "outputs": [],
      "source": [
        "def test(model, dataloader, loss_fn):\n",
        "  total_loss, correct = 0., 0\n",
        "  for i, data in enumerate(dataloader):\n",
        "    with torch.no_grad():\n",
        "      X, y = data\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      model.eval()\n",
        "      outputs = model(X)\n",
        "      correct += (outputs.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "      loss = loss_fn(outputs, y)\n",
        "      total_loss += loss.item()\n",
        "  print(f'Test Accuracy: {correct/len(dataloader.dataset)} Avg Loss: {total_loss/len(dataloader):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmLAjj7BoxSx",
        "outputId": "490d9bfd-8b7a-45ba-f07c-50f71cf68105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1 ---------------------------------\n",
            "Loss: 2.327 [0/60000]\n",
            "Loss: 2.315 [6400/60000]\n",
            "Loss: 2.320 [12800/60000]\n",
            "Loss: 2.308 [19200/60000]\n",
            "Loss: 2.301 [25600/60000]\n",
            "Loss: 2.315 [32000/60000]\n",
            "Loss: 2.301 [38400/60000]\n",
            "Loss: 2.300 [44800/60000]\n",
            "Loss: 2.313 [51200/60000]\n",
            "Loss: 2.308 [57600/60000]\n",
            "Test Accuracy: 0.1156 Avg Loss: 2.292\n",
            "\n"
          ]
        }
      ],
      "source": [
        "epochs=1\n",
        "for i in range(epochs):\n",
        "  print(f'Epochs: {i+1} ---------------------------------')\n",
        "  train(model, trainloader, loss_fn, optimizer)\n",
        "  test(model, testloader, loss_fn)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcIm9C03vSnh"
      },
      "source": [
        "## Ray Tune\n",
        "___Hyper Parameter Tuning___  \n",
        "___Using Model classifying CIFAR-10___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPiDLW7_vKvy"
      },
      "source": [
        "It is referred to \n",
        " - _https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html_\n",
        " - _https://docs.ray.io/en/latest/tune/index.html_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3PRiTNNA53J"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/Colab Notebooks/Pytorch'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQfifTxKvH3i"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# install the package needed\n",
        "!pip install ray[tune]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzA76diKxJKg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# for hyper parameter tuning, only need to import 3 modules\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AJgWlVbT-b-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "s6T0aGsDVJC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFB_GbYyNWBo"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNFcZa6sx--2"
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir=\"./data\"):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=True, download=True, transform=transform)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    return trainset, testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMR0Q9V7BIew"
      },
      "source": [
        "```\n",
        "transforms.Normalize(  \n",
        "    mean,  \n",
        "    std,  \n",
        "    inplace=False \n",
        ")\n",
        "```\n",
        "mean and std is applied for each channel of image  \n",
        "Ex) 'mean=(0, 0, 0)' matchs 3 channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1Sf_ZWDNQ1-",
        "outputId": "e24cf86f-e114-4cdd-adc7-93b89c555293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = data_path + '/RayTune'\n",
        "train_ds, test_ds = load_data(path)\n",
        "len(train_ds), len(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNevW9VJNRg5"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ojtll29UBfv-"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, l1, l2):\n",
        "    super().__init__()\n",
        "    self.conv_1 = nn.Conv2d(3, 6, 5)\n",
        "    self.conv_2 = nn.Conv2d(6, 16, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    self.fc_1 = nn.Linear(16*5*5, l1)\n",
        "    self.fc_2 = nn.Linear(l1, l2)\n",
        "    self.fc_3 = nn.Linear(l2, 10)\n",
        "\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.pool(F.relu(self.conv_1(x)))\n",
        "    out = self.pool(F.relu(self.conv_2(out)))\n",
        "    out = torch.flatten(out, 1)\n",
        "\n",
        "    out = F.relu(self.fc_1(out))\n",
        "    out = F.relu(self.fc_2(out))\n",
        "    logits = self.fc_2(out)\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ_Dpg0Xrcym"
      },
      "outputs": [],
      "source": [
        "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
        "  sw = True\n",
        "  net = Net(config['l1'], config['l2'])\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  if device == 'cude':\n",
        "    if torch.cuda.device_count() > 1:\n",
        "      net = nn.DataParallel(net)\n",
        "  net.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(), lr=config['lr'], momentum=0.9)\n",
        "\n",
        "  if checkpoint_dir:\n",
        "    model_state, optimizer_state = torch.load(\n",
        "        os.path.join(checkpoint_dir, \"checkpoint\"))\n",
        "    net.load_state_dict(model_state)\n",
        "    optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "  train_ds, test_ds = load_data(data_dir)\n",
        "  len_train = int(len(train_ds)*0.8)\n",
        "  train_subset, val_subset = random_split\n",
        "\n",
        "  len_train = int(len(train_ds)*0.8)\n",
        "  train_ds, val_ds = random_split(train_ds, [len_train, len(train_ds)-len_train])\n",
        "  \n",
        "  trainloader = torch.utils.data.DataLoader(\n",
        "                    train_ds,\n",
        "                    batch_size=int(config['batch_size']),\n",
        "                    shuffle=True,\n",
        "                    num_workers=8\n",
        "  )\n",
        "  valloader = torch.utils.data.DataLoader(\n",
        "                    val_ds,\n",
        "                    batch_size=int(config['batch_size']),\n",
        "                    shuffle=True,\n",
        "                    num_workers=8\n",
        "  )\n",
        "\n",
        "  for epoch in range(10):\n",
        "    running_loss = 0.\n",
        "    epoch_steps = 0\n",
        "    for i, data in enumerate(trainloader):\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      epoch_steps += 1\n",
        "      if i % 2000 == 1999:\n",
        "        print(\"[%d, %5d] loss: %.3f\" % (epoch+1, epoch_steps, running_loss/epoch_steps))\n",
        "      \n",
        "    val_loss = 0.\n",
        "    val_steps = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, data in enumerate(valloader):\n",
        "      with torch.no_grad():\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        ###\n",
        "        if sw:\n",
        "          print(type(outputs))\n",
        "          print(outputs.data)\n",
        "          sw = False\n",
        "        ###\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        correct += (pred.item() == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss += loss.cpu().numpy()\n",
        "        val_steps += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8ZdZZqX1Tj3"
      },
      "source": [
        "### 실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVEfsfP1rKDy"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6a_nmJ5rKD1"
      },
      "source": [
        "Most of the imports are needed for building the PyTorch model. Only the last three\n",
        "imports are for Ray Tune.\n",
        "\n",
        "Data loaders\n",
        "------------\n",
        "We wrap the data loaders in their own function and pass a global data directory.\n",
        "This way we can share a data directory between different trials.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwK9K40-rKD2"
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir=\"./data\"):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=True, download=True, transform=transform)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    return trainset, testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41W1lObprKD3"
      },
      "source": [
        "Configurable neural network\n",
        "---------------------------\n",
        "We can only tune those parameters that are configurable. In this example, we can specify\n",
        "the layer sizes of the fully connected layers:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSGhT1jfrKD4"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, l1=120, l2=84):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
        "        self.fc2 = nn.Linear(l1, l2)\n",
        "        self.fc3 = nn.Linear(l2, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0mAqSkjrKD5"
      },
      "source": [
        "The train function\n",
        "------------------\n",
        "Now it gets interesting, because we introduce some changes to the example `from the PyTorch\n",
        "documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.\n",
        "\n",
        "We wrap the training script in a function ``train_cifar(config, checkpoint_dir=None, data_dir=None)``.\n",
        "As you can guess, the ``config`` parameter will receive the hyperparameters we would like to\n",
        "train with. The ``checkpoint_dir`` parameter is used to restore checkpoints. The ``data_dir`` specifies\n",
        "the directory where we load and store the data, so multiple runs can share the same data source.\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    net = Net(config[\"l1\"], config[\"l2\"])\n",
        "\n",
        "    if checkpoint_dir:\n",
        "        model_state, optimizer_state = torch.load(\n",
        "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
        "        net.load_state_dict(model_state)\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "The learning rate of the optimizer is made configurable, too:\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
        "\n",
        "We also split the training data into a training and validation subset. We thus train on\n",
        "80% of the data and calculate the validation loss on the remaining 20%. The batch sizes\n",
        "with which we iterate through the training and test sets are configurable as well.\n",
        "\n",
        "Adding (multi) GPU support with DataParallel\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Image classification benefits largely from GPUs. Luckily, we can continue to use\n",
        "PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``\n",
        "to support data parallel training on multiple GPUs:\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            net = nn.DataParallel(net)\n",
        "    net.to(device)\n",
        "\n",
        "By using a ``device`` variable we make sure that training also works when we have\n",
        "no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,\n",
        "like this:\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray\n",
        "also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_\n",
        "so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back\n",
        "to that later.\n",
        "\n",
        "Communicating with Ray Tune\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "The most interesting part is the communication with Ray Tune:\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
        "        path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "        torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
        "\n",
        "Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,\n",
        "we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics\n",
        "to decide which hyperparameter configuration lead to the best results. These metrics\n",
        "can also be used to stop bad performing trials early in order to avoid wasting\n",
        "resources on those trials.\n",
        "\n",
        "The checkpoint saving is optional, however, it is necessary if we wanted to use advanced\n",
        "schedulers like\n",
        "`Population Based Training <https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html>`_.\n",
        "Also, by saving the checkpoint we can later load the trained models and validate them\n",
        "on a test set.\n",
        "\n",
        "Full training function\n",
        "~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "The full code example looks like this:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWFuw15jrKD7"
      },
      "outputs": [],
      "source": [
        "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
        "    net = Net(config[\"l1\"], config[\"l2\"])\n",
        "\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            net = nn.DataParallel(net)\n",
        "    net.to(device)\n",
        "    ##################################################\n",
        "    print(next(net.parameters()).is_cuda)\n",
        "    ##################################################\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
        "\n",
        "    if checkpoint_dir:\n",
        "        model_state, optimizer_state = torch.load(\n",
        "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
        "        net.load_state_dict(model_state)\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "    trainset, testset = load_data(data_dir)\n",
        "\n",
        "    test_abs = int(len(trainset) * 0.8)\n",
        "    train_subset, val_subset = random_split(\n",
        "        trainset, [test_abs, len(trainset) - test_abs])\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=int(config[\"batch_size\"]),\n",
        "        shuffle=True,\n",
        "        num_workers=2)\n",
        "    valloader = torch.utils.data.DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=int(config[\"batch_size\"]),\n",
        "        shuffle=True,\n",
        "        num_workers=2)\n",
        "\n",
        "    for epoch in range(10):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        epoch_steps = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            epoch_steps += 1\n",
        "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
        "                                                running_loss / epoch_steps))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Validation loss\n",
        "        val_loss = 0.0\n",
        "        val_steps = 0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for i, data in enumerate(valloader, 0):\n",
        "            with torch.no_grad():\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = net(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.cpu().numpy()\n",
        "                val_steps += 1\n",
        "\n",
        "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
        "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
        "    print(\"Finished Training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Djl9wGAHnLHh"
      },
      "outputs": [],
      "source": [
        "def test_accuracy(net, device=\"cpu\"):\n",
        "    trainset, testset = load_data()\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uJcjSKwzAkA",
        "outputId": "0a4ceab9-a5a2-475c-8ded-3d96a4d4b0bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-02 09:25:57,304\tWARNING tune.py:669 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Current time: 2022-08-02 09:25:57 (running for 00:00:00.19)\n",
            "Memory usage on this node: 1.7/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+-----------------+--------------+------+------+-------------+\n",
            "| Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |\n",
            "|-------------------------+----------+-----------------+--------------+------+------+-------------|\n",
            "| train_cifar_1d5ca_00000 | RUNNING  | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 |\n",
            "| train_cifar_1d5ca_00001 | PENDING  |                 |           16 |  256 |   16 | 0.00029796  |\n",
            "| train_cifar_1d5ca_00002 | PENDING  |                 |            2 |   16 |  128 | 0.0285343   |\n",
            "| train_cifar_1d5ca_00003 | PENDING  |                 |            8 |    8 |   64 | 0.00449389  |\n",
            "| train_cifar_1d5ca_00004 | PENDING  |                 |           16 |  128 |    8 | 0.00134106  |\n",
            "| train_cifar_1d5ca_00005 | PENDING  |                 |            8 |   16 |  128 | 0.0156025   |\n",
            "| train_cifar_1d5ca_00006 | PENDING  |                 |            4 |   32 |  128 | 0.000169008 |\n",
            "| train_cifar_1d5ca_00007 | PENDING  |                 |            2 |  256 |   64 | 0.0241508   |\n",
            "| train_cifar_1d5ca_00008 | PENDING  |                 |            4 |   64 |   64 | 0.00753399  |\n",
            "| train_cifar_1d5ca_00009 | PENDING  |                 |            4 |    8 |   16 | 0.000993305 |\n",
            "+-------------------------+----------+-----------------+--------------+------+------+-------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m   cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:38:44 (running for 00:12:47.18)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00004 | RUNNING    | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.14701 |     0.5942 |                    9 |\n",
            "| train_cifar_1d5ca_00005 | PENDING    |                 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [10,  2000] loss: 0.982\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:38:49 (running for 00:12:52.20)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00004 | RUNNING    | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.14701 |     0.5942 |                    9 |\n",
            "| train_cifar_1d5ca_00005 | PENDING    |                 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:38:54 (running for 00:12:57.22)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00004 | RUNNING    | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.14701 |     0.5942 |                    9 |\n",
            "| train_cifar_1d5ca_00005 | PENDING    |                 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00004:\n",
            "  accuracy: 0.5938\n",
            "  date: 2022-08-02_09-38-58\n",
            "  done: true\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 10\n",
            "  loss: 1.171369725227356\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 335.4252893924713\n",
            "  time_this_iter_s: 34.52102828025818\n",
            "  time_total_s: 335.4252893924713\n",
            "  timestamp: 1659433138\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 10\n",
            "  trial_id: 1d5ca_00004\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:39:03 (running for 00:13:06.57)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:39:08 (running for 00:13:11.60)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:39:13 (running for 00:13:16.65)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  2000] loss: 2.015\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:39:18 (running for 00:13:21.66)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:39:24 (running for 00:13:26.72)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:39:29 (running for 00:13:31.73)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  4000] loss: 0.948\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:39:34 (running for 00:13:36.75)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:39:39 (running for 00:13:41.77)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:39:44 (running for 00:13:46.83)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   |         |            |                      |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00005:\n",
            "  accuracy: 0.3279\n",
            "  date: 2022-08-02_09-39-46\n",
            "  done: false\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.8377911224842072\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 47.88441562652588\n",
            "  time_this_iter_s: 47.88441562652588\n",
            "  time_total_s: 47.88441562652588\n",
            "  timestamp: 1659433186\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1d5ca_00005\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:39:51 (running for 00:13:54.47)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.83779 |     0.3279 |                    1 |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:39:56 (running for 00:13:59.52)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.83779 |     0.3279 |                    1 |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2,  2000] loss: 1.854\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:01 (running for 00:14:04.53)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.83779 |     0.3279 |                    1 |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:06 (running for 00:14:09.56)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.83779 |     0.3279 |                    1 |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:11 (running for 00:14:14.59)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.83779 |     0.3279 |                    1 |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:16 (running for 00:14:19.64)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.83779 |     0.3279 |                    1 |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2,  4000] loss: 0.947\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:21 (running for 00:14:24.65)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.83779 |     0.3279 |                    1 |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:27 (running for 00:14:29.70)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.83779 |     0.3279 |                    1 |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:32 (running for 00:14:34.72)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5103348220825195 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00005 | RUNNING    | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.83779 |     0.3279 |                    1 |\n",
            "| train_cifar_1d5ca_00006 | PENDING    |                 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00005:\n",
            "  accuracy: 0.295\n",
            "  date: 2022-08-02_09-40-34\n",
            "  done: true\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 2\n",
            "  loss: 1.8768785871982574\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 95.21035718917847\n",
            "  time_this_iter_s: 47.32594156265259\n",
            "  time_total_s: 95.21035718917847\n",
            "  timestamp: 1659433234\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: 1d5ca_00005\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:39 (running for 00:14:41.85)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:44 (running for 00:14:46.88)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  2000] loss: 2.303\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:49 (running for 00:14:51.91)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:54 (running for 00:14:56.93)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:40:59 (running for 00:15:01.95)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  4000] loss: 1.149\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:41:04 (running for 00:15:06.98)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:41:09 (running for 00:15:12.02)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  6000] loss: 0.759\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:41:14 (running for 00:15:17.04)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:41:19 (running for 00:15:22.07)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:41:24 (running for 00:15:27.09)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  8000] loss: 0.541\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:41:29 (running for 00:15:32.11)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:41:34 (running for 00:15:37.14)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1, 10000] loss: 0.395\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:41:39 (running for 00:15:42.16)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:41:44 (running for 00:15:47.17)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00006 | RUNNING    | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 |         |            |                      |\n",
            "| train_cifar_1d5ca_00007 | PENDING    |                 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00006:\n",
            "  accuracy: 0.2939\n",
            "  date: 2022-08-02_09-41-48\n",
            "  done: true\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.9352432904958725\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 74.48182392120361\n",
            "  time_this_iter_s: 74.48182392120361\n",
            "  time_total_s: 74.48182392120361\n",
            "  timestamp: 1659433308\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1d5ca_00006\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:41:53 (running for 00:15:56.33)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:41:58 (running for 00:16:01.34)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:03 (running for 00:16:06.35)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  2000] loss: 2.326\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:08 (running for 00:16:11.37)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:13 (running for 00:16:16.39)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:18 (running for 00:16:21.40)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  4000] loss: 1.158\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:23 (running for 00:16:26.44)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:28 (running for 00:16:31.47)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:33 (running for 00:16:36.50)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:38 (running for 00:16:41.52)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  6000] loss: 0.776\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:43 (running for 00:16:46.53)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:48 (running for 00:16:51.55)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:53 (running for 00:16:56.56)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  8000] loss: 0.582\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:42:58 (running for 00:17:01.58)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:03 (running for 00:17:06.61)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:08 (running for 00:17:11.63)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1, 10000] loss: 0.466\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:13 (running for 00:17:16.64)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:18 (running for 00:17:21.66)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:23 (running for 00:17:26.67)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:28 (running for 00:17:31.68)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1, 12000] loss: 0.388\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:34 (running for 00:17:36.71)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:39 (running for 00:17:41.73)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:44 (running for 00:17:46.76)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1, 14000] loss: 0.333\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:49 (running for 00:17:51.77)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:54 (running for 00:17:56.80)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:43:59 (running for 00:18:01.82)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1, 16000] loss: 0.291\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:44:04 (running for 00:18:06.84)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:44:09 (running for 00:18:11.85)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:44:14 (running for 00:18:16.87)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:44:19 (running for 00:18:21.89)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1, 18000] loss: 0.259\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:44:24 (running for 00:18:26.92)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:44:29 (running for 00:18:31.94)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:44:34 (running for 00:18:36.96)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1, 20000] loss: 0.233\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:44:39 (running for 00:18:41.97)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:44:44 (running for 00:18:46.99)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:44:49 (running for 00:18:52.01)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:44:54 (running for 00:18:57.04)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00007 | RUNNING    | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   |         |            |                      |\n",
            "| train_cifar_1d5ca_00008 | PENDING    |                 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00007:\n",
            "  accuracy: 0.0976\n",
            "  date: 2022-08-02_09-44-57\n",
            "  done: true\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 1\n",
            "  loss: 2.3338784604549407\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 189.29606699943542\n",
            "  time_this_iter_s: 189.29606699943542\n",
            "  time_total_s: 189.29606699943542\n",
            "  timestamp: 1659433497\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1d5ca_00007\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:02 (running for 00:19:05.64)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:07 (running for 00:19:10.67)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  2000] loss: 2.080\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:13 (running for 00:19:15.71)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:18 (running for 00:19:20.73)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:23 (running for 00:19:25.74)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  4000] loss: 0.954\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:28 (running for 00:19:30.76)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:33 (running for 00:19:35.77)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  6000] loss: 0.622\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:38 (running for 00:19:40.82)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:43 (running for 00:19:45.85)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:48 (running for 00:19:50.87)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  8000] loss: 0.462\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:53 (running for 00:19:55.89)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:45:58 (running for 00:20:00.93)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1, 10000] loss: 0.369\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:03 (running for 00:20:05.94)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:08 (running for 00:20:10.96)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:13 (running for 00:20:15.98)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.9052645113825797\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  |         |            |                      |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00008:\n",
            "  accuracy: 0.3452\n",
            "  date: 2022-08-02_09-46-13\n",
            "  done: false\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.8052232707381248\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 75.95253801345825\n",
            "  time_this_iter_s: 75.95253801345825\n",
            "  time_total_s: 75.95253801345825\n",
            "  timestamp: 1659433573\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1d5ca_00008\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:18 (running for 00:20:21.68)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:23 (running for 00:20:26.69)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2,  2000] loss: 1.834\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:29 (running for 00:20:31.74)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:34 (running for 00:20:36.76)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2,  4000] loss: 0.920\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:39 (running for 00:20:41.79)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:44 (running for 00:20:46.81)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:49 (running for 00:20:51.83)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2,  6000] loss: 0.615\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:54 (running for 00:20:56.84)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:46:59 (running for 00:21:01.87)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:47:04 (running for 00:21:06.89)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2,  8000] loss: 0.462\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:47:09 (running for 00:21:11.92)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:47:14 (running for 00:21:16.93)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2, 10000] loss: 0.372\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:47:19 (running for 00:21:21.99)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:47:24 (running for 00:21:27.00)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00008 | RUNNING    | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.80522 |     0.3452 |                    1 |\n",
            "| train_cifar_1d5ca_00009 | PENDING    |                 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00008:\n",
            "  accuracy: 0.3315\n",
            "  date: 2022-08-02_09-47-29\n",
            "  done: true\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 2\n",
            "  loss: 1.88244076872468\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 151.32208776474\n",
            "  time_this_iter_s: 75.36954975128174\n",
            "  time_total_s: 151.32208776474\n",
            "  timestamp: 1659433649\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: 1d5ca_00008\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:47:34 (running for 00:21:37.01)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:47:39 (running for 00:21:42.05)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  2000] loss: 2.284\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:47:44 (running for 00:21:47.06)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:47:49 (running for 00:21:52.08)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  4000] loss: 1.034\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:47:54 (running for 00:21:57.11)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:47:59 (running for 00:22:02.12)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  6000] loss: 0.622\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:48:04 (running for 00:22:07.14)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:48:09 (running for 00:22:12.16)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1,  8000] loss: 0.421\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:48:14 (running for 00:22:17.18)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:48:19 (running for 00:22:22.23)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [1, 10000] loss: 0.317\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:48:24 (running for 00:22:27.24)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:48:29 (running for 00:22:32.27)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.875285732269287\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 |         |            |                      |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00009:\n",
            "  accuracy: 0.4088\n",
            "  date: 2022-08-02_09-48-31\n",
            "  done: false\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.5618103302121162\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 62.03284978866577\n",
            "  time_this_iter_s: 62.03284978866577\n",
            "  time_total_s: 62.03284978866577\n",
            "  timestamp: 1659433711\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1d5ca_00009\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:48:36 (running for 00:22:39.04)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2,  2000] loss: 1.530\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:48:41 (running for 00:22:44.06)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:48:46 (running for 00:22:49.07)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2,  4000] loss: 0.760\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:48:51 (running for 00:22:54.08)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:48:56 (running for 00:22:59.10)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2,  6000] loss: 0.493\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:01 (running for 00:23:04.15)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:06 (running for 00:23:09.17)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:11 (running for 00:23:14.20)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2,  8000] loss: 0.356\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:16 (running for 00:23:19.21)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:21 (running for 00:23:24.23)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [2, 10000] loss: 0.284\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:26 (running for 00:23:29.25)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:31 (running for 00:23:34.26)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.613180613899231 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.56181 |     0.4088 |                    1 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00009:\n",
            "  accuracy: 0.4971\n",
            "  date: 2022-08-02_09-49-31\n",
            "  done: false\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 2\n",
            "  loss: 1.3630037526607512\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 122.47736287117004\n",
            "  time_this_iter_s: 60.44451308250427\n",
            "  time_total_s: 122.47736287117004\n",
            "  timestamp: 1659433771\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: 1d5ca_00009\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:36 (running for 00:23:39.49)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.363   |     0.4971 |                    2 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [3,  2000] loss: 1.375\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:41 (running for 00:23:44.51)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.363   |     0.4971 |                    2 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:46 (running for 00:23:49.52)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.363   |     0.4971 |                    2 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [3,  4000] loss: 0.691\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:51 (running for 00:23:54.54)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.363   |     0.4971 |                    2 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:49:56 (running for 00:23:59.55)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.363   |     0.4971 |                    2 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [3,  6000] loss: 0.454\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:01 (running for 00:24:04.60)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.363   |     0.4971 |                    2 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:06 (running for 00:24:09.62)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.363   |     0.4971 |                    2 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [3,  8000] loss: 0.338\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:11 (running for 00:24:14.65)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.363   |     0.4971 |                    2 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:16 (running for 00:24:19.65)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.363   |     0.4971 |                    2 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [3, 10000] loss: 0.266\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:21 (running for 00:24:24.69)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.363   |     0.4971 |                    2 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:27 (running for 00:24:29.70)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.363   |     0.4971 |                    2 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00009:\n",
            "  accuracy: 0.5296\n",
            "  date: 2022-08-02_09-50-29\n",
            "  done: false\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 3\n",
            "  loss: 1.3069172286629678\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 180.5162637233734\n",
            "  time_this_iter_s: 58.03890085220337\n",
            "  time_total_s: 180.5162637233734\n",
            "  timestamp: 1659433829\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 3\n",
            "  trial_id: 1d5ca_00009\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:34 (running for 00:24:37.54)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [4,  2000] loss: 1.309\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:39 (running for 00:24:42.55)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:44 (running for 00:24:47.57)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [4,  4000] loss: 0.659\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:49 (running for 00:24:52.58)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:54 (running for 00:24:57.60)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [4,  6000] loss: 0.428\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:50:59 (running for 00:25:02.61)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:51:04 (running for 00:25:07.64)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [4,  8000] loss: 0.325\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:51:09 (running for 00:25:12.65)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:51:14 (running for 00:25:17.66)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [4, 10000] loss: 0.252\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:51:19 (running for 00:25:22.68)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:51:25 (running for 00:25:27.72)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:51:30 (running for 00:25:32.76)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.3863436827659608 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.30692 |     0.5296 |                    3 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00009:\n",
            "  accuracy: 0.5112\n",
            "  date: 2022-08-02_09-51-30\n",
            "  done: false\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 4\n",
            "  loss: 1.368046187132597\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 241.66229724884033\n",
            "  time_this_iter_s: 61.14603352546692\n",
            "  time_total_s: 241.66229724884033\n",
            "  timestamp: 1659433890\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 4\n",
            "  trial_id: 1d5ca_00009\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:51:35 (running for 00:25:38.68)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.36805 |     0.5112 |                    4 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:51:40 (running for 00:25:43.69)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.36805 |     0.5112 |                    4 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [5,  2000] loss: 1.252\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:51:46 (running for 00:25:48.71)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.36805 |     0.5112 |                    4 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [5,  4000] loss: 0.625\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:51:51 (running for 00:25:53.73)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.36805 |     0.5112 |                    4 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:51:56 (running for 00:25:58.76)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.36805 |     0.5112 |                    4 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [5,  6000] loss: 0.416\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:01 (running for 00:26:03.76)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.36805 |     0.5112 |                    4 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:06 (running for 00:26:08.78)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.36805 |     0.5112 |                    4 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [5,  8000] loss: 0.310\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:11 (running for 00:26:13.79)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.36805 |     0.5112 |                    4 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:16 (running for 00:26:18.83)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.36805 |     0.5112 |                    4 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [5, 10000] loss: 0.251\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:21 (running for 00:26:23.84)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.36805 |     0.5112 |                    4 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:26 (running for 00:26:28.86)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.36805 |     0.5112 |                    4 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00009:\n",
            "  accuracy: 0.5418\n",
            "  date: 2022-08-02_09-52-29\n",
            "  done: false\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 5\n",
            "  loss: 1.27556403131783\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 300.32375288009644\n",
            "  time_this_iter_s: 58.6614556312561\n",
            "  time_total_s: 300.32375288009644\n",
            "  timestamp: 1659433949\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 5\n",
            "  trial_id: 1d5ca_00009\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:34 (running for 00:26:37.33)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.27556 |     0.5418 |                    5 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:39 (running for 00:26:42.35)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.27556 |     0.5418 |                    5 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [6,  2000] loss: 1.211\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:44 (running for 00:26:47.36)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.27556 |     0.5418 |                    5 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [6,  4000] loss: 0.608\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:49 (running for 00:26:52.40)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.27556 |     0.5418 |                    5 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:54 (running for 00:26:57.42)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.27556 |     0.5418 |                    5 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [6,  6000] loss: 0.404\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:52:59 (running for 00:27:02.44)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.27556 |     0.5418 |                    5 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:53:04 (running for 00:27:07.46)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.27556 |     0.5418 |                    5 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [6,  8000] loss: 0.304\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:53:09 (running for 00:27:12.51)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.27556 |     0.5418 |                    5 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:53:14 (running for 00:27:17.52)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.27556 |     0.5418 |                    5 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [6, 10000] loss: 0.247\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:53:19 (running for 00:27:22.54)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.27556 |     0.5418 |                    5 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:53:24 (running for 00:27:27.54)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.27556 |     0.5418 |                    5 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00009:\n",
            "  accuracy: 0.5596\n",
            "  date: 2022-08-02_09-53-28\n",
            "  done: false\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 6\n",
            "  loss: 1.2486832472652196\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 359.282683134079\n",
            "  time_this_iter_s: 58.958930253982544\n",
            "  time_total_s: 359.282683134079\n",
            "  timestamp: 1659434008\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 6\n",
            "  trial_id: 1d5ca_00009\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:53:33 (running for 00:27:36.32)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:53:38 (running for 00:27:41.33)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [7,  2000] loss: 1.180\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:53:43 (running for 00:27:46.36)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:53:48 (running for 00:27:51.37)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [7,  4000] loss: 0.592\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:53:53 (running for 00:27:56.39)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:53:58 (running for 00:28:01.40)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [7,  6000] loss: 0.407\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:03 (running for 00:28:06.44)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:08 (running for 00:28:11.46)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [7,  8000] loss: 0.297\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:13 (running for 00:28:16.47)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:18 (running for 00:28:21.48)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [7, 10000] loss: 0.241\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:23 (running for 00:28:26.51)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:28 (running for 00:28:31.52)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.24868 |     0.5596 |                    6 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_1d5ca_00009:\n",
            "  accuracy: 0.5784\n",
            "  date: 2022-08-02_09-54-29\n",
            "  done: false\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 7\n",
            "  loss: 1.2037151560783386\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 419.79200434684753\n",
            "  time_this_iter_s: 60.509321212768555\n",
            "  time_total_s: 419.79200434684753\n",
            "  timestamp: 1659434069\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 7\n",
            "  trial_id: 1d5ca_00009\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:34 (running for 00:28:36.82)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.20372 |     0.5784 |                    7 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [8,  2000] loss: 1.171\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:39 (running for 00:28:41.85)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.20372 |     0.5784 |                    7 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:44 (running for 00:28:46.87)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.20372 |     0.5784 |                    7 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [8,  4000] loss: 0.597\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:49 (running for 00:28:51.89)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.20372 |     0.5784 |                    7 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:54 (running for 00:28:56.92)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.20372 |     0.5784 |                    7 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [8,  6000] loss: 0.394\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:54:59 (running for 00:29:01.93)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.20372 |     0.5784 |                    7 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:55:04 (running for 00:29:06.98)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.20372 |     0.5784 |                    7 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [8,  8000] loss: 0.292\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:55:09 (running for 00:29:12.00)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.20372 |     0.5784 |                    7 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:55:14 (running for 00:29:17.04)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.20372 |     0.5784 |                    7 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=3068)\u001b[0m [8, 10000] loss: 0.235\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:55:19 (running for 00:29:22.07)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.20372 |     0.5784 |                    7 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:55:24 (running for 00:29:27.09)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.2329583477973938 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00009 | RUNNING    | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.20372 |     0.5784 |                    7 |\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-02 09:55:28,404\tINFO tune.py:748 -- Total run time: 1771.11 seconds (1770.97 seconds for the tuning loop).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result for train_cifar_1d5ca_00009:\n",
            "  accuracy: 0.523\n",
            "  date: 2022-08-02_09-55-28\n",
            "  done: true\n",
            "  experiment_id: ada73034c878484d8be947b50b1a6628\n",
            "  hostname: 3c87a96c0fb6\n",
            "  iterations_since_restore: 8\n",
            "  loss: 1.3947163203209638\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3068\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 478.96084237098694\n",
            "  time_this_iter_s: 59.168838024139404\n",
            "  time_total_s: 478.96084237098694\n",
            "  timestamp: 1659434128\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 8\n",
            "  trial_id: 1d5ca_00009\n",
            "  warmup_time: 0.0030655860900878906\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-08-02 09:55:28 (running for 00:29:30.99)\n",
            "Memory usage on this node: 1.9/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=10\n",
            "Bracket: Iter 8.000: -1.2538961165428162 | Iter 4.000: -1.377194934949279 | Iter 2.000: -1.5617577179908753 | Iter 1.000: -1.8565384273767471\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-08-02_09-25-57\n",
            "Number of trials: 10/10 (10 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_1d5ca_00000 | TERMINATED | 172.28.0.2:3068 |           16 |   64 |   64 | 0.000852711 | 1.16311 |     0.5953 |                   10 |\n",
            "| train_cifar_1d5ca_00001 | TERMINATED | 172.28.0.2:3068 |           16 |  256 |   16 | 0.00029796  | 2.22674 |     0.1934 |                    1 |\n",
            "| train_cifar_1d5ca_00002 | TERMINATED | 172.28.0.2:3068 |            2 |   16 |  128 | 0.0285343   | 2.32098 |     0.1032 |                    1 |\n",
            "| train_cifar_1d5ca_00003 | TERMINATED | 172.28.0.2:3068 |            8 |    8 |   64 | 0.00449389  | 1.44947 |     0.477  |                    4 |\n",
            "| train_cifar_1d5ca_00004 | TERMINATED | 172.28.0.2:3068 |           16 |  128 |    8 | 0.00134106  | 1.17137 |     0.5938 |                   10 |\n",
            "| train_cifar_1d5ca_00005 | TERMINATED | 172.28.0.2:3068 |            8 |   16 |  128 | 0.0156025   | 1.87688 |     0.295  |                    2 |\n",
            "| train_cifar_1d5ca_00006 | TERMINATED | 172.28.0.2:3068 |            4 |   32 |  128 | 0.000169008 | 1.93524 |     0.2939 |                    1 |\n",
            "| train_cifar_1d5ca_00007 | TERMINATED | 172.28.0.2:3068 |            2 |  256 |   64 | 0.0241508   | 2.33388 |     0.0976 |                    1 |\n",
            "| train_cifar_1d5ca_00008 | TERMINATED | 172.28.0.2:3068 |            4 |   64 |   64 | 0.00753399  | 1.88244 |     0.3315 |                    2 |\n",
            "| train_cifar_1d5ca_00009 | TERMINATED | 172.28.0.2:3068 |            4 |    8 |   16 | 0.000993305 | 1.39472 |     0.523  |                    8 |\n",
            "+-------------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Best trial config: {'l1': 64, 'l2': 64, 'lr': 0.0008527110699258408, 'batch_size': 16}\n",
            "Best trial final validation loss: 1.163112868309021\n",
            "Best trial final validation accuracy: 0.5953\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Best trial test set accuracy: 0.5948\n"
          ]
        }
      ],
      "source": [
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
        "    data_dir = os.path.abspath(\"./data\")\n",
        "    load_data(data_dir)\n",
        "    config = {\n",
        "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
        "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
        "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "        \"batch_size\": tune.choice([2, 4, 8, 16])\n",
        "    }\n",
        "    scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=max_num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "    reporter = CLIReporter(\n",
        "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
        "    result = tune.run(\n",
        "        partial(train_cifar, data_dir=data_dir),\n",
        "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter)\n",
        "\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\n",
        "    print(\"Best trial final validation loss: {}\".format(\n",
        "        best_trial.last_result[\"loss\"]))\n",
        "    print(\"Best trial final validation accuracy: {}\".format(\n",
        "        best_trial.last_result[\"accuracy\"]))\n",
        "\n",
        "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if gpus_per_trial > 1:\n",
        "            best_trained_model = nn.DataParallel(best_trained_model)\n",
        "    best_trained_model.to(device)\n",
        "\n",
        "    best_checkpoint_dir = best_trial.checkpoint.value\n",
        "    model_state, optimizer_state = torch.load(os.path.join(\n",
        "        best_checkpoint_dir, \"checkpoint\"))\n",
        "    best_trained_model.load_state_dict(model_state)\n",
        "\n",
        "    test_acc = test_accuracy(best_trained_model, device)\n",
        "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # You can change the number of GPUs per trial here:\n",
        "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogWkolXBzCW7",
        "outputId": "57ad4f84-9849-4ab4-c7f4-e94f0e34fb1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-02 10:01:54,980\tWARNING session.py:35 -- Session not detected. You should not be calling `checkpoint_dir` outside `tune.run` or while using the class API. \n",
            "2022-08-02 10:01:54,982\tWARNING session.py:38 --   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
            "    handler_func(fileobj, events)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-52-27a10ade2083>\", line 7, in <module>\n",
            "    train_cifar(config, data_dir=data_path)\n",
            "  File \"<ipython-input-51-6d1d656b4b62>\", line 84, in train_cifar\n",
            "    with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 112, in __enter__\n",
            "    return next(self.gen)\n",
            "\n",
            "2022-08-02 10:01:55,028\tWARNING session.py:35 -- Session not detected. You should not be calling `report` outside `tune.run` or while using the class API. \n",
            "2022-08-02 10:01:55,030\tWARNING session.py:38 --   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
            "    handler_func(fileobj, events)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-52-27a10ade2083>\", line 7, in <module>\n",
            "    train_cifar(config, data_dir=data_path)\n",
            "  File \"<ipython-input-51-6d1d656b4b62>\", line 88, in train_cifar\n",
            "    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "data_path = './data'\n",
        "\n",
        "config = {'lr': 1e-3,\n",
        "          'l1': 8,\n",
        "          'l2': 16,\n",
        "          'batch_size': 64}\n",
        "train_cifar(config, data_dir=data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u__y4pu9_5aJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Pytorch_RayTune.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}